{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66dd5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36231ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "data=pd.read_csv('C:/Users/Ishit/Desktop/birds_rev2/birds.csv')\n",
    "bird_family= pd.read_csv('C:/Users/Ishit/Desktop/birds_rev2/class_dict.csv')\n",
    "train_data = data[data['data set']=='train'][['filepaths', 'labels']]\n",
    "valid_data = data[data['data set']=='valid'][['filepaths', 'labels']]\n",
    "test_data = data[data['data set']=='test'][['filepaths', 'labels']]\n",
    "valid_data.iloc[0]\n",
    "class Alexnetdataset(Dataset):\n",
    "    def __init__(self, datafr, path, class_dict, transform = None):\n",
    "        self.datafr = datafr\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.class_dict = class_dict\n",
    "    def __len__(self):\n",
    "        return self.datafr.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = os.path.join(self.path, self.datafr.iloc[idx][0])\n",
    "        img = plt.imread(img_path)\n",
    "        label = self.class_dict[self.datafr.iloc[idx][1]]\n",
    "        \n",
    "        if self.transform :\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14c6e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict={}\n",
    "for i in range(275):\n",
    "    class_dict[bird_family.loc[i][1]] = i\n",
    "new_dict = {}\n",
    "for i in class_dict:\n",
    "    new_dict[class_dict[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27ff481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "train_dataset = Alexnetdataset(datafr = train_data, path = 'birds_rev2/', class_dict = class_dict, transform = torchvision.transforms.functional.to_tensor)\n",
    "test_dataset  = Alexnetdataset(datafr = test_data, path = 'birds_rev2/', class_dict = class_dict, transform = torchvision.transforms.functional.to_tensor)\n",
    "valid_dataset= Alexnetdataset(datafr = valid_data, path = 'birds_rev2/', class_dict = class_dict, transform = torchvision.transforms.functional.to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773eb421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=1200, bias=True)\n",
      "  (fc3): Linear(in_features=1200, out_features=275, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3,96,11,4)\n",
    "            self.conv2 = nn.Conv2d(96,256,5,padding=2,groups=2)\n",
    "            self.conv3 = nn.Conv2d(256,384,3,padding=1)\n",
    "            self.conv4 = nn.Conv2d(384,384,3,padding=1, groups=2)\n",
    "            self.conv5 = nn.Conv2d(384,256,3,padding=1, groups=2)\n",
    "            self.fc1 = nn.Linear(256*6*6,4096)\n",
    "            self.fc2 = nn.Linear(4096,1200)\n",
    "            self.fc3 = nn.Linear(1200,275)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv5(x)),(2,2))\n",
    "        x = x.view(x.size(0),256*6*6)\n",
    "        x = F.dropout(F.relu(self.fc1(x)),p=0.5)\n",
    "        x = F.dropout(F.relu(self.fc2(x)),p=0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "print(model)\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "061bf5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.61612691116333, Valid loss: 5.618093285994096\n",
      "Valid accuracy: 0.2909090909090909\n",
      "Train loss: 5.6162694597244265, Valid loss: 5.617561664581299\n",
      "Valid accuracy: 0.36363636363636365\n",
      "Train loss: 5.616176947911581, Valid loss: 5.6202578804709695\n",
      "Valid accuracy: 0.2181818181818182\n",
      "Train loss: 5.615155924320221, Valid loss: 5.62149825703014\n",
      "Valid accuracy: 0.36363636363636365\n",
      "Train loss: 5.614368057632446, Valid loss: 5.618117214549671\n",
      "Valid accuracy: 0.36363636363636365\n",
      "Train loss: 5.6143237415949505, Valid loss: 5.617853334600275\n",
      "Valid accuracy: 0.36363636363636365\n",
      "Train loss: 5.614391444887434, Valid loss: 5.618372575586492\n",
      "Valid accuracy: 0.36363636363636365\n",
      "Train loss: 5.61398072886467, Valid loss: 5.620440644350919\n",
      "Valid accuracy: 0.14545454545454545\n",
      "Train loss: 5.613728430642022, Valid loss: 5.622511203072288\n",
      "Valid accuracy: 0.5090909090909091\n",
      "Train loss: 5.613330438041687, Valid loss: 5.621490100513805\n",
      "Valid accuracy: 0.36363636363636365\n",
      "Train loss: 5.612492546428333, Valid loss: 5.638813480030406\n",
      "Valid accuracy: 0.4363636363636364\n",
      "Train loss: 5.609678637504578, Valid loss: 5.517275340340354\n",
      "Valid accuracy: 0.7272727272727273\n",
      "Train loss: 5.598228899735671, Valid loss: 5.358522342335094\n",
      "Valid accuracy: 1.5272727272727273\n",
      "Train loss: 5.577931889533996, Valid loss: 5.211312335621227\n",
      "Valid accuracy: 2.0363636363636366\n",
      "Train loss: 5.551383847808838, Valid loss: 5.1207013078169386\n",
      "Valid accuracy: 1.6727272727272726\n",
      "Train loss: 4.961707385063171, Valid loss: 4.849377372048118\n",
      "Valid accuracy: 4.1454545454545455\n",
      "Train loss: 4.92568876695633, Valid loss: 4.749611408927224\n",
      "Valid accuracy: 4.0\n",
      "Train loss: 4.860317896842957, Valid loss: 4.672560365850275\n",
      "Valid accuracy: 5.6000000000000005\n",
      "Train loss: 4.817478663444519, Valid loss: 4.496729051416571\n",
      "Valid accuracy: 6.036363636363636\n",
      "Train loss: 4.7820200290679935, Valid loss: 4.453190019780939\n",
      "Valid accuracy: 6.327272727272727\n",
      "Train loss: 4.738788568019867, Valid loss: 4.366725503748113\n",
      "Valid accuracy: 6.836363636363636\n",
      "Train loss: 4.6918972328730995, Valid loss: 4.27599255995317\n",
      "Valid accuracy: 9.018181818181818\n",
      "Train loss: 4.647747541308403, Valid loss: 4.226710948944092\n",
      "Valid accuracy: 9.018181818181818\n",
      "Train loss: 4.616969119389852, Valid loss: 4.177013487382369\n",
      "Valid accuracy: 9.309090909090909\n",
      "Train loss: 4.574868486404419, Valid loss: 4.029269275665283\n",
      "Valid accuracy: 10.836363636363638\n",
      "Train loss: 4.536754290840842, Valid loss: 3.9238147830963133\n",
      "Valid accuracy: 13.018181818181818\n",
      "Train loss: 4.502301473458608, Valid loss: 3.945188085382635\n",
      "Valid accuracy: 13.600000000000001\n",
      "Train loss: 4.4689460323773895, Valid loss: 3.7806116433577106\n",
      "Valid accuracy: 14.254545454545456\n",
      "Train loss: 4.43507461799894, Valid loss: 3.7086839242414995\n",
      "Valid accuracy: 17.09090909090909\n",
      "Train loss: 4.399659296607971, Valid loss: 3.654424521706321\n",
      "Valid accuracy: 18.545454545454547\n",
      "Train loss: 3.6995918312072753, Valid loss: 3.5417902166193183\n",
      "Valid accuracy: 20.363636363636363\n",
      "Train loss: 3.698528885602951, Valid loss: 3.4837702907215466\n",
      "Valid accuracy: 20.0\n",
      "Train loss: 3.6806178878148397, Valid loss: 3.4229879743402654\n",
      "Valid accuracy: 21.818181818181817\n",
      "Train loss: 3.65575327706337, Valid loss: 3.327917339151556\n",
      "Valid accuracy: 22.545454545454547\n",
      "Train loss: 3.628714214324951, Valid loss: 3.330417947769165\n",
      "Valid accuracy: 22.10909090909091\n",
      "Train loss: 3.610056850274404, Valid loss: 3.240349429737438\n",
      "Valid accuracy: 25.96363636363636\n",
      "Train loss: 3.5840991641453335, Valid loss: 3.1801466525684705\n",
      "Valid accuracy: 24.0\n",
      "Train loss: 3.5595720686912538, Valid loss: 3.0757343248887494\n",
      "Valid accuracy: 26.836363636363636\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pic should be 2/3 dimensional. Got 0 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-235a7653d50f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtot_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-c31eaed1444e>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pic should be 2/3 dimensional. Got {} dimensions.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mdefault_float_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pic should be 2/3 dimensional. Got 0 dimensions."
     ]
    }
   ],
   "source": [
    "epochs =10 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(train_dataset, batch_size = 15, shuffle = True)\n",
    "validation_loader = DataLoader(valid_dataset, batch_size = 15, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 15, shuffle = True)\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.\n",
    "    validation_loss = 0.\n",
    "    valid_right = 0\n",
    "    tot_train = 0\n",
    "    i = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        prediction = nn.functional.log_softmax(model(x), dim=1)\n",
    "        loss = loss_fn(prediction, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        train_loss += loss.item()*x.size(0)\n",
    "        tot_train += x.size(0)        \n",
    "        x.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "        i += 1\n",
    "        if i%250 == 0:\n",
    "            validation_loss = 0\n",
    "            valid_right = 0\n",
    "            model.eval()\n",
    "            for x, y in validation_loader:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                prediction = model(x)\n",
    "                loss = (loss_fn(prediction, y))\n",
    "                validation_loss += loss.item()*x.size(0)\n",
    "                valid_right += (nn.functional.softmax(prediction,dim = 1).argmax(1)==y).sum().item()\n",
    "            print(f'Train loss: {train_loss/tot_train}, Valid loss: {validation_loss/len(validation_loader.dataset)}',f'Valid accuracy: {valid_right/len(validation_loader.dataset)*100}', sep = '\\n')\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

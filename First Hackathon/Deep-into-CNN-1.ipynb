{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e4035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f96a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 75) (40000, 75)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0    5\n",
       " 1    5\n",
       " 2    1\n",
       " 3    7\n",
       " 4    1\n",
       " Name: target, dtype: int64,\n",
       " 160000    0\n",
       " 160001    5\n",
       " 160002    2\n",
       " 160003    1\n",
       " 160004    1\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"C:/Users/Ishit/Desktop/train.csv\")\n",
    "final_test=pd.read_csv(\"C:/Users/Ishit/Desktop/test.csv\")\n",
    "iden=final_test.id.copy()\n",
    "data=data.loc[:,data.columns != \"id\"]\n",
    "final_test=final_test.loc[:,final_test.columns != \"id\"]\n",
    "data=data.replace({\"Class_1\"},0)\n",
    "data=data.replace({\"Class_2\"},1)\n",
    "data=data.replace({\"Class_3\"},2)\n",
    "data=data.replace({\"Class_4\"},3)\n",
    "data=data.replace({\"Class_5\"},4)\n",
    "data=data.replace({\"Class_6\"},5)\n",
    "data=data.replace({\"Class_7\"},6)\n",
    "data=data.replace({\"Class_8\"},7)\n",
    "data=data.replace({\"Class_9\"},8)\n",
    "\n",
    "col = [str(i) for i in range(0,75)]\n",
    "final_test.columns = col\n",
    "col.append('target')\n",
    "data.columns = col\n",
    "col.pop(-1)\n",
    "data[col] = data[col]/data[col].max()\n",
    "\n",
    "split=160000\n",
    "x = data[:split][col]\n",
    "y = data[:split].target\n",
    "xt = data[split:][col]\n",
    "yt = data[split:].target\n",
    "print(x.shape, xt.shape)\n",
    "y.head(), yt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f6a216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0938, 0.0143, 0.0000, 0.0000, 0.0000, 0.0000, 0.1842,\n",
       "         0.0000, 0.0000, 0.0000, 0.0811, 0.0000, 0.0312, 0.0000, 0.0000, 0.2143,\n",
       "         0.1364, 0.0038, 0.0000, 0.0606, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0095, 0.0000, 0.0000, 0.0256, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0536, 0.0000, 0.0263, 0.0833,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0125, 0.0098,\n",
       "         0.0000, 0.0000, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0328, 0.0000, 0.0000]),\n",
       " tensor(5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.tensor(x.values.astype(np.float32))\n",
    "train_y = torch.tensor(y.values.astype(np.int64))\n",
    "train_x[0], train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642748af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0196, 0.2031, 0.1143, 0.0000, 0.0658, 0.0233, 0.0000, 0.0526,\n",
       "         0.0000, 0.0303, 0.0000, 0.0000, 0.0000, 0.0312, 0.0000, 0.0000, 0.0000,\n",
       "         0.3182, 0.0000, 0.0333, 0.0000, 0.0000, 0.1818, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0256, 0.0641, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0294, 0.0000, 0.1224, 0.0000, 0.0274, 0.0000, 0.0159, 0.0741,\n",
       "         0.0000, 0.0000, 0.0309, 0.0000, 0.1316, 0.0000, 0.0137, 0.0526, 0.0278,\n",
       "         0.0000, 0.0000, 0.0652, 0.0000, 0.0333, 0.0028, 0.0043, 0.0250, 0.0588,\n",
       "         0.0000, 0.2800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
       "         0.0656, 0.3154, 0.0577]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = torch.tensor(xt.values.astype(np.float32))\n",
    "test_y = torch.tensor(yt.values.astype(np.int64))\n",
    "test_x[0], test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "724b9a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.mydataset at 0x22d23d49a60>,\n",
       " <__main__.mydataset at 0x22d23d59160>,\n",
       " (tensor([0.0000, 0.0000, 0.0938, 0.0143, 0.0000, 0.0000, 0.0000, 0.0000, 0.1842,\n",
       "          0.0000, 0.0000, 0.0000, 0.0811, 0.0000, 0.0312, 0.0000, 0.0000, 0.2143,\n",
       "          0.1364, 0.0038, 0.0000, 0.0606, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0095, 0.0000, 0.0000, 0.0256, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0536, 0.0000, 0.0263, 0.0833,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0125, 0.0098,\n",
       "          0.0000, 0.0000, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0328, 0.0000, 0.0000]),\n",
       "  tensor(5)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class mydataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self,idx):\n",
    "        item = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return (item,label)\n",
    "training_data = mydataset(train_x,train_y)\n",
    "testing_data = mydataset(test_x,test_y)\n",
    "training_data, testing_data, next(iter(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78301cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "train_dataloader= torch.utils.data.DataLoader(training_data,batch_size=batch_size)\n",
    "test_dataloader= torch.utils.data.DataLoader(testing_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319424f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten= nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "            nn.Linear(75,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,9),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        logits= self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89ab376c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=75, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=9, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec320c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaa7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41964ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786770cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.194272  [    0/160000]\n",
      "loss: 2.146138  [10000/160000]\n",
      "loss: 2.089509  [20000/160000]\n",
      "loss: 2.018619  [30000/160000]\n",
      "loss: 2.068237  [40000/160000]\n",
      "loss: 1.894754  [50000/160000]\n",
      "loss: 1.964463  [60000/160000]\n",
      "loss: 2.018481  [70000/160000]\n",
      "loss: 1.899026  [80000/160000]\n",
      "loss: 2.055381  [90000/160000]\n",
      "loss: 1.900743  [100000/160000]\n",
      "loss: 1.967668  [110000/160000]\n",
      "loss: 1.979128  [120000/160000]\n",
      "loss: 1.880884  [130000/160000]\n",
      "loss: 1.941927  [140000/160000]\n",
      "loss: 1.869071  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 25.9%, Avg loss: 0.019197 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.876452  [    0/160000]\n",
      "loss: 2.014608  [10000/160000]\n",
      "loss: 1.940943  [20000/160000]\n",
      "loss: 1.847537  [30000/160000]\n",
      "loss: 2.002988  [40000/160000]\n",
      "loss: 1.792114  [50000/160000]\n",
      "loss: 1.923121  [60000/160000]\n",
      "loss: 2.014712  [70000/160000]\n",
      "loss: 1.838631  [80000/160000]\n",
      "loss: 2.057376  [90000/160000]\n",
      "loss: 1.884014  [100000/160000]\n",
      "loss: 1.953006  [110000/160000]\n",
      "loss: 1.958408  [120000/160000]\n",
      "loss: 1.896206  [130000/160000]\n",
      "loss: 1.939580  [140000/160000]\n",
      "loss: 1.846411  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 26.4%, Avg loss: 0.019134 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.874963  [    0/160000]\n",
      "loss: 2.006674  [10000/160000]\n",
      "loss: 1.930018  [20000/160000]\n",
      "loss: 1.834966  [30000/160000]\n",
      "loss: 1.995853  [40000/160000]\n",
      "loss: 1.787083  [50000/160000]\n",
      "loss: 1.920705  [60000/160000]\n",
      "loss: 2.011289  [70000/160000]\n",
      "loss: 1.829044  [80000/160000]\n",
      "loss: 2.052354  [90000/160000]\n",
      "loss: 1.881440  [100000/160000]\n",
      "loss: 1.946882  [110000/160000]\n",
      "loss: 1.958844  [120000/160000]\n",
      "loss: 1.892498  [130000/160000]\n",
      "loss: 1.935672  [140000/160000]\n",
      "loss: 1.841709  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 29.0%, Avg loss: 0.019078 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.872365  [    0/160000]\n",
      "loss: 2.005580  [10000/160000]\n",
      "loss: 1.921493  [20000/160000]\n",
      "loss: 1.823898  [30000/160000]\n",
      "loss: 1.987142  [40000/160000]\n",
      "loss: 1.781020  [50000/160000]\n",
      "loss: 1.917081  [60000/160000]\n",
      "loss: 2.003444  [70000/160000]\n",
      "loss: 1.819845  [80000/160000]\n",
      "loss: 2.041445  [90000/160000]\n",
      "loss: 1.878671  [100000/160000]\n",
      "loss: 1.938476  [110000/160000]\n",
      "loss: 1.961871  [120000/160000]\n",
      "loss: 1.886137  [130000/160000]\n",
      "loss: 1.930682  [140000/160000]\n",
      "loss: 1.836562  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 29.5%, Avg loss: 0.019001 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.869273  [    0/160000]\n",
      "loss: 2.004863  [10000/160000]\n",
      "loss: 1.908888  [20000/160000]\n",
      "loss: 1.808152  [30000/160000]\n",
      "loss: 1.974197  [40000/160000]\n",
      "loss: 1.773632  [50000/160000]\n",
      "loss: 1.902825  [60000/160000]\n",
      "loss: 1.974389  [70000/160000]\n",
      "loss: 1.802196  [80000/160000]\n",
      "loss: 2.021667  [90000/160000]\n",
      "loss: 1.853662  [100000/160000]\n",
      "loss: 1.898035  [110000/160000]\n",
      "loss: 1.958385  [120000/160000]\n",
      "loss: 1.842021  [130000/160000]\n",
      "loss: 1.897023  [140000/160000]\n",
      "loss: 1.842530  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 29.7%, Avg loss: 0.018776 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.831501  [    0/160000]\n",
      "loss: 2.015807  [10000/160000]\n",
      "loss: 1.860479  [20000/160000]\n",
      "loss: 1.798156  [30000/160000]\n",
      "loss: 1.940193  [40000/160000]\n",
      "loss: 1.777805  [50000/160000]\n",
      "loss: 1.868487  [60000/160000]\n",
      "loss: 1.945886  [70000/160000]\n",
      "loss: 1.777971  [80000/160000]\n",
      "loss: 2.018392  [90000/160000]\n",
      "loss: 1.841398  [100000/160000]\n",
      "loss: 1.877211  [110000/160000]\n",
      "loss: 1.963698  [120000/160000]\n",
      "loss: 1.837061  [130000/160000]\n",
      "loss: 1.892617  [140000/160000]\n",
      "loss: 1.836013  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 29.7%, Avg loss: 0.018687 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.826922  [    0/160000]\n",
      "loss: 2.018804  [10000/160000]\n",
      "loss: 1.839287  [20000/160000]\n",
      "loss: 1.783017  [30000/160000]\n",
      "loss: 1.924272  [40000/160000]\n",
      "loss: 1.774282  [50000/160000]\n",
      "loss: 1.862859  [60000/160000]\n",
      "loss: 1.938043  [70000/160000]\n",
      "loss: 1.767816  [80000/160000]\n",
      "loss: 2.008955  [90000/160000]\n",
      "loss: 1.839851  [100000/160000]\n",
      "loss: 1.868868  [110000/160000]\n",
      "loss: 1.972583  [120000/160000]\n",
      "loss: 1.835786  [130000/160000]\n",
      "loss: 1.892894  [140000/160000]\n",
      "loss: 1.831581  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 30.0%, Avg loss: 0.018614 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.826956  [    0/160000]\n",
      "loss: 2.019790  [10000/160000]\n",
      "loss: 1.822924  [20000/160000]\n",
      "loss: 1.772387  [30000/160000]\n",
      "loss: 1.912905  [40000/160000]\n",
      "loss: 1.770906  [50000/160000]\n",
      "loss: 1.854926  [60000/160000]\n",
      "loss: 1.932194  [70000/160000]\n",
      "loss: 1.761434  [80000/160000]\n",
      "loss: 2.001689  [90000/160000]\n",
      "loss: 1.839134  [100000/160000]\n",
      "loss: 1.863183  [110000/160000]\n",
      "loss: 1.978837  [120000/160000]\n",
      "loss: 1.834736  [130000/160000]\n",
      "loss: 1.892589  [140000/160000]\n",
      "loss: 1.829300  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 32.3%, Avg loss: 0.018548 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.827378  [    0/160000]\n",
      "loss: 2.019858  [10000/160000]\n",
      "loss: 1.808128  [20000/160000]\n",
      "loss: 1.766025  [30000/160000]\n",
      "loss: 1.905080  [40000/160000]\n",
      "loss: 1.765942  [50000/160000]\n",
      "loss: 1.845561  [60000/160000]\n",
      "loss: 1.927843  [70000/160000]\n",
      "loss: 1.755682  [80000/160000]\n",
      "loss: 1.997054  [90000/160000]\n",
      "loss: 1.838635  [100000/160000]\n",
      "loss: 1.857676  [110000/160000]\n",
      "loss: 1.981951  [120000/160000]\n",
      "loss: 1.833398  [130000/160000]\n",
      "loss: 1.890093  [140000/160000]\n",
      "loss: 1.829351  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 33.4%, Avg loss: 0.018486 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.827485  [    0/160000]\n",
      "loss: 2.018989  [10000/160000]\n",
      "loss: 1.794535  [20000/160000]\n",
      "loss: 1.762842  [30000/160000]\n",
      "loss: 1.899823  [40000/160000]\n",
      "loss: 1.763022  [50000/160000]\n",
      "loss: 1.836430  [60000/160000]\n",
      "loss: 1.924154  [70000/160000]\n",
      "loss: 1.749912  [80000/160000]\n",
      "loss: 1.993909  [90000/160000]\n",
      "loss: 1.837068  [100000/160000]\n",
      "loss: 1.849500  [110000/160000]\n",
      "loss: 1.982578  [120000/160000]\n",
      "loss: 1.829757  [130000/160000]\n",
      "loss: 1.885269  [140000/160000]\n",
      "loss: 1.831112  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 33.9%, Avg loss: 0.018429 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.827496  [    0/160000]\n",
      "loss: 2.017505  [10000/160000]\n",
      "loss: 1.781666  [20000/160000]\n",
      "loss: 1.761334  [30000/160000]\n",
      "loss: 1.896124  [40000/160000]\n",
      "loss: 1.761922  [50000/160000]\n",
      "loss: 1.825090  [60000/160000]\n",
      "loss: 1.920221  [70000/160000]\n",
      "loss: 1.743659  [80000/160000]\n",
      "loss: 1.991963  [90000/160000]\n",
      "loss: 1.834772  [100000/160000]\n",
      "loss: 1.841735  [110000/160000]\n",
      "loss: 1.979195  [120000/160000]\n",
      "loss: 1.826361  [130000/160000]\n",
      "loss: 1.879530  [140000/160000]\n",
      "loss: 1.834051  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.1%, Avg loss: 0.018378 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.827815  [    0/160000]\n",
      "loss: 2.014905  [10000/160000]\n",
      "loss: 1.770341  [20000/160000]\n",
      "loss: 1.760852  [30000/160000]\n",
      "loss: 1.894017  [40000/160000]\n",
      "loss: 1.762042  [50000/160000]\n",
      "loss: 1.814842  [60000/160000]\n",
      "loss: 1.916825  [70000/160000]\n",
      "loss: 1.737167  [80000/160000]\n",
      "loss: 1.990834  [90000/160000]\n",
      "loss: 1.833175  [100000/160000]\n",
      "loss: 1.834913  [110000/160000]\n",
      "loss: 1.974047  [120000/160000]\n",
      "loss: 1.821727  [130000/160000]\n",
      "loss: 1.874245  [140000/160000]\n",
      "loss: 1.837424  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.2%, Avg loss: 0.018336 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.829108  [    0/160000]\n",
      "loss: 2.011874  [10000/160000]\n",
      "loss: 1.761267  [20000/160000]\n",
      "loss: 1.760151  [30000/160000]\n",
      "loss: 1.891930  [40000/160000]\n",
      "loss: 1.762512  [50000/160000]\n",
      "loss: 1.805982  [60000/160000]\n",
      "loss: 1.914132  [70000/160000]\n",
      "loss: 1.731756  [80000/160000]\n",
      "loss: 1.988705  [90000/160000]\n",
      "loss: 1.832353  [100000/160000]\n",
      "loss: 1.829562  [110000/160000]\n",
      "loss: 1.968717  [120000/160000]\n",
      "loss: 1.817175  [130000/160000]\n",
      "loss: 1.869709  [140000/160000]\n",
      "loss: 1.839638  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.2%, Avg loss: 0.018302 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.830272  [    0/160000]\n",
      "loss: 2.009493  [10000/160000]\n",
      "loss: 1.754264  [20000/160000]\n",
      "loss: 1.759549  [30000/160000]\n",
      "loss: 1.890388  [40000/160000]\n",
      "loss: 1.762728  [50000/160000]\n",
      "loss: 1.798698  [60000/160000]\n",
      "loss: 1.911978  [70000/160000]\n",
      "loss: 1.727332  [80000/160000]\n",
      "loss: 1.986295  [90000/160000]\n",
      "loss: 1.831324  [100000/160000]\n",
      "loss: 1.825120  [110000/160000]\n",
      "loss: 1.964276  [120000/160000]\n",
      "loss: 1.812207  [130000/160000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.866179  [140000/160000]\n",
      "loss: 1.840891  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.3%, Avg loss: 0.018274 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.830817  [    0/160000]\n",
      "loss: 2.007550  [10000/160000]\n",
      "loss: 1.749359  [20000/160000]\n",
      "loss: 1.758910  [30000/160000]\n",
      "loss: 1.889328  [40000/160000]\n",
      "loss: 1.761724  [50000/160000]\n",
      "loss: 1.792510  [60000/160000]\n",
      "loss: 1.909668  [70000/160000]\n",
      "loss: 1.724328  [80000/160000]\n",
      "loss: 1.984398  [90000/160000]\n",
      "loss: 1.830923  [100000/160000]\n",
      "loss: 1.821657  [110000/160000]\n",
      "loss: 1.960086  [120000/160000]\n",
      "loss: 1.806692  [130000/160000]\n",
      "loss: 1.863599  [140000/160000]\n",
      "loss: 1.840713  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.3%, Avg loss: 0.018248 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.831617  [    0/160000]\n",
      "loss: 2.004587  [10000/160000]\n",
      "loss: 1.746415  [20000/160000]\n",
      "loss: 1.758093  [30000/160000]\n",
      "loss: 1.888692  [40000/160000]\n",
      "loss: 1.759739  [50000/160000]\n",
      "loss: 1.787006  [60000/160000]\n",
      "loss: 1.907452  [70000/160000]\n",
      "loss: 1.722440  [80000/160000]\n",
      "loss: 1.981724  [90000/160000]\n",
      "loss: 1.830258  [100000/160000]\n",
      "loss: 1.819026  [110000/160000]\n",
      "loss: 1.956351  [120000/160000]\n",
      "loss: 1.800859  [130000/160000]\n",
      "loss: 1.861755  [140000/160000]\n",
      "loss: 1.839442  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.4%, Avg loss: 0.018224 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.832001  [    0/160000]\n",
      "loss: 2.001512  [10000/160000]\n",
      "loss: 1.744539  [20000/160000]\n",
      "loss: 1.756953  [30000/160000]\n",
      "loss: 1.887478  [40000/160000]\n",
      "loss: 1.757397  [50000/160000]\n",
      "loss: 1.781971  [60000/160000]\n",
      "loss: 1.905281  [70000/160000]\n",
      "loss: 1.720712  [80000/160000]\n",
      "loss: 1.979411  [90000/160000]\n",
      "loss: 1.829031  [100000/160000]\n",
      "loss: 1.817053  [110000/160000]\n",
      "loss: 1.952888  [120000/160000]\n",
      "loss: 1.795321  [130000/160000]\n",
      "loss: 1.860611  [140000/160000]\n",
      "loss: 1.837825  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.4%, Avg loss: 0.018201 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.832066  [    0/160000]\n",
      "loss: 1.998725  [10000/160000]\n",
      "loss: 1.742798  [20000/160000]\n",
      "loss: 1.755880  [30000/160000]\n",
      "loss: 1.886382  [40000/160000]\n",
      "loss: 1.755025  [50000/160000]\n",
      "loss: 1.777313  [60000/160000]\n",
      "loss: 1.902960  [70000/160000]\n",
      "loss: 1.719410  [80000/160000]\n",
      "loss: 1.977522  [90000/160000]\n",
      "loss: 1.828050  [100000/160000]\n",
      "loss: 1.814790  [110000/160000]\n",
      "loss: 1.948993  [120000/160000]\n",
      "loss: 1.789684  [130000/160000]\n",
      "loss: 1.859711  [140000/160000]\n",
      "loss: 1.835891  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.4%, Avg loss: 0.018178 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.831904  [    0/160000]\n",
      "loss: 1.996126  [10000/160000]\n",
      "loss: 1.741282  [20000/160000]\n",
      "loss: 1.754379  [30000/160000]\n",
      "loss: 1.885312  [40000/160000]\n",
      "loss: 1.753214  [50000/160000]\n",
      "loss: 1.773016  [60000/160000]\n",
      "loss: 1.900459  [70000/160000]\n",
      "loss: 1.718523  [80000/160000]\n",
      "loss: 1.975908  [90000/160000]\n",
      "loss: 1.827522  [100000/160000]\n",
      "loss: 1.812664  [110000/160000]\n",
      "loss: 1.945276  [120000/160000]\n",
      "loss: 1.784297  [130000/160000]\n",
      "loss: 1.859168  [140000/160000]\n",
      "loss: 1.833977  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 0.018155 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.831702  [    0/160000]\n",
      "loss: 1.993761  [10000/160000]\n",
      "loss: 1.739911  [20000/160000]\n",
      "loss: 1.752655  [30000/160000]\n",
      "loss: 1.884342  [40000/160000]\n",
      "loss: 1.751815  [50000/160000]\n",
      "loss: 1.768750  [60000/160000]\n",
      "loss: 1.898272  [70000/160000]\n",
      "loss: 1.717897  [80000/160000]\n",
      "loss: 1.974869  [90000/160000]\n",
      "loss: 1.827358  [100000/160000]\n",
      "loss: 1.810313  [110000/160000]\n",
      "loss: 1.941703  [120000/160000]\n",
      "loss: 1.779729  [130000/160000]\n",
      "loss: 1.856941  [140000/160000]\n",
      "loss: 1.832285  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 0.018129 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.832689  [    0/160000]\n",
      "loss: 1.990228  [10000/160000]\n",
      "loss: 1.737606  [20000/160000]\n",
      "loss: 1.750027  [30000/160000]\n",
      "loss: 1.882759  [40000/160000]\n",
      "loss: 1.747270  [50000/160000]\n",
      "loss: 1.764416  [60000/160000]\n",
      "loss: 1.898169  [70000/160000]\n",
      "loss: 1.717087  [80000/160000]\n",
      "loss: 1.968262  [90000/160000]\n",
      "loss: 1.828581  [100000/160000]\n",
      "loss: 1.806627  [110000/160000]\n",
      "loss: 1.939265  [120000/160000]\n",
      "loss: 1.773693  [130000/160000]\n",
      "loss: 1.845653  [140000/160000]\n",
      "loss: 1.835859  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.6%, Avg loss: 0.018065 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.825302  [    0/160000]\n",
      "loss: 1.983125  [10000/160000]\n",
      "loss: 1.725485  [20000/160000]\n",
      "loss: 1.737905  [30000/160000]\n",
      "loss: 1.882150  [40000/160000]\n",
      "loss: 1.740115  [50000/160000]\n",
      "loss: 1.764479  [60000/160000]\n",
      "loss: 1.901022  [70000/160000]\n",
      "loss: 1.717081  [80000/160000]\n",
      "loss: 1.958664  [90000/160000]\n",
      "loss: 1.825170  [100000/160000]\n",
      "loss: 1.803436  [110000/160000]\n",
      "loss: 1.939055  [120000/160000]\n",
      "loss: 1.770319  [130000/160000]\n",
      "loss: 1.842229  [140000/160000]\n",
      "loss: 1.838259  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.6%, Avg loss: 0.018030 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.818717  [    0/160000]\n",
      "loss: 1.978838  [10000/160000]\n",
      "loss: 1.716395  [20000/160000]\n",
      "loss: 1.731044  [30000/160000]\n",
      "loss: 1.881136  [40000/160000]\n",
      "loss: 1.739527  [50000/160000]\n",
      "loss: 1.764765  [60000/160000]\n",
      "loss: 1.900447  [70000/160000]\n",
      "loss: 1.715966  [80000/160000]\n",
      "loss: 1.958295  [90000/160000]\n",
      "loss: 1.822523  [100000/160000]\n",
      "loss: 1.801575  [110000/160000]\n",
      "loss: 1.935129  [120000/160000]\n",
      "loss: 1.766770  [130000/160000]\n",
      "loss: 1.840675  [140000/160000]\n",
      "loss: 1.836821  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.7%, Avg loss: 0.018006 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.816588  [    0/160000]\n",
      "loss: 1.973799  [10000/160000]\n",
      "loss: 1.711948  [20000/160000]\n",
      "loss: 1.726894  [30000/160000]\n",
      "loss: 1.880082  [40000/160000]\n",
      "loss: 1.739610  [50000/160000]\n",
      "loss: 1.763164  [60000/160000]\n",
      "loss: 1.898870  [70000/160000]\n",
      "loss: 1.716341  [80000/160000]\n",
      "loss: 1.956715  [90000/160000]\n",
      "loss: 1.820511  [100000/160000]\n",
      "loss: 1.800296  [110000/160000]\n",
      "loss: 1.930080  [120000/160000]\n",
      "loss: 1.760409  [130000/160000]\n",
      "loss: 1.839750  [140000/160000]\n",
      "loss: 1.834255  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.017984 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.816425  [    0/160000]\n",
      "loss: 1.968569  [10000/160000]\n",
      "loss: 1.708970  [20000/160000]\n",
      "loss: 1.723120  [30000/160000]\n",
      "loss: 1.878002  [40000/160000]\n",
      "loss: 1.739302  [50000/160000]\n",
      "loss: 1.761802  [60000/160000]\n",
      "loss: 1.896920  [70000/160000]\n",
      "loss: 1.717144  [80000/160000]\n",
      "loss: 1.954517  [90000/160000]\n",
      "loss: 1.817505  [100000/160000]\n",
      "loss: 1.799165  [110000/160000]\n",
      "loss: 1.925192  [120000/160000]\n",
      "loss: 1.753591  [130000/160000]\n",
      "loss: 1.838913  [140000/160000]\n",
      "loss: 1.832789  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.017965 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.816348  [    0/160000]\n",
      "loss: 1.964349  [10000/160000]\n",
      "loss: 1.706473  [20000/160000]\n",
      "loss: 1.719347  [30000/160000]\n",
      "loss: 1.876140  [40000/160000]\n",
      "loss: 1.738463  [50000/160000]\n",
      "loss: 1.760034  [60000/160000]\n",
      "loss: 1.895026  [70000/160000]\n",
      "loss: 1.717304  [80000/160000]\n",
      "loss: 1.952566  [90000/160000]\n",
      "loss: 1.814455  [100000/160000]\n",
      "loss: 1.798013  [110000/160000]\n",
      "loss: 1.921926  [120000/160000]\n",
      "loss: 1.748629  [130000/160000]\n",
      "loss: 1.838725  [140000/160000]\n",
      "loss: 1.831687  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.017948 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.817139  [    0/160000]\n",
      "loss: 1.960716  [10000/160000]\n",
      "loss: 1.704921  [20000/160000]\n",
      "loss: 1.716725  [30000/160000]\n",
      "loss: 1.874979  [40000/160000]\n",
      "loss: 1.738369  [50000/160000]\n",
      "loss: 1.758605  [60000/160000]\n",
      "loss: 1.892882  [70000/160000]\n",
      "loss: 1.717358  [80000/160000]\n",
      "loss: 1.950785  [90000/160000]\n",
      "loss: 1.812254  [100000/160000]\n",
      "loss: 1.796508  [110000/160000]\n",
      "loss: 1.919173  [120000/160000]\n",
      "loss: 1.743988  [130000/160000]\n",
      "loss: 1.838705  [140000/160000]\n",
      "loss: 1.830701  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.017933 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.818093  [    0/160000]\n",
      "loss: 1.957110  [10000/160000]\n",
      "loss: 1.703790  [20000/160000]\n",
      "loss: 1.714559  [30000/160000]\n",
      "loss: 1.874297  [40000/160000]\n",
      "loss: 1.737939  [50000/160000]\n",
      "loss: 1.757307  [60000/160000]\n",
      "loss: 1.890782  [70000/160000]\n",
      "loss: 1.717042  [80000/160000]\n",
      "loss: 1.949445  [90000/160000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.809685  [100000/160000]\n",
      "loss: 1.795268  [110000/160000]\n",
      "loss: 1.916563  [120000/160000]\n",
      "loss: 1.739235  [130000/160000]\n",
      "loss: 1.838737  [140000/160000]\n",
      "loss: 1.829700  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.017919 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.819400  [    0/160000]\n",
      "loss: 1.953792  [10000/160000]\n",
      "loss: 1.703164  [20000/160000]\n",
      "loss: 1.712713  [30000/160000]\n",
      "loss: 1.873469  [40000/160000]\n",
      "loss: 1.737391  [50000/160000]\n",
      "loss: 1.755782  [60000/160000]\n",
      "loss: 1.889046  [70000/160000]\n",
      "loss: 1.716759  [80000/160000]\n",
      "loss: 1.948102  [90000/160000]\n",
      "loss: 1.807400  [100000/160000]\n",
      "loss: 1.793884  [110000/160000]\n",
      "loss: 1.914460  [120000/160000]\n",
      "loss: 1.734820  [130000/160000]\n",
      "loss: 1.838700  [140000/160000]\n",
      "loss: 1.828575  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.017907 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.820360  [    0/160000]\n",
      "loss: 1.950700  [10000/160000]\n",
      "loss: 1.702545  [20000/160000]\n",
      "loss: 1.711027  [30000/160000]\n",
      "loss: 1.873059  [40000/160000]\n",
      "loss: 1.736438  [50000/160000]\n",
      "loss: 1.754472  [60000/160000]\n",
      "loss: 1.887548  [70000/160000]\n",
      "loss: 1.716817  [80000/160000]\n",
      "loss: 1.946823  [90000/160000]\n",
      "loss: 1.805291  [100000/160000]\n",
      "loss: 1.792049  [110000/160000]\n",
      "loss: 1.912528  [120000/160000]\n",
      "loss: 1.730795  [130000/160000]\n",
      "loss: 1.838793  [140000/160000]\n",
      "loss: 1.827567  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.017895 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.821377  [    0/160000]\n",
      "loss: 1.948133  [10000/160000]\n",
      "loss: 1.701614  [20000/160000]\n",
      "loss: 1.709409  [30000/160000]\n",
      "loss: 1.872822  [40000/160000]\n",
      "loss: 1.735646  [50000/160000]\n",
      "loss: 1.753463  [60000/160000]\n",
      "loss: 1.886470  [70000/160000]\n",
      "loss: 1.716808  [80000/160000]\n",
      "loss: 1.945708  [90000/160000]\n",
      "loss: 1.803099  [100000/160000]\n",
      "loss: 1.790340  [110000/160000]\n",
      "loss: 1.910571  [120000/160000]\n",
      "loss: 1.727338  [130000/160000]\n",
      "loss: 1.838798  [140000/160000]\n",
      "loss: 1.826608  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.017885 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.822357  [    0/160000]\n",
      "loss: 1.945853  [10000/160000]\n",
      "loss: 1.701308  [20000/160000]\n",
      "loss: 1.708068  [30000/160000]\n",
      "loss: 1.872662  [40000/160000]\n",
      "loss: 1.734954  [50000/160000]\n",
      "loss: 1.752724  [60000/160000]\n",
      "loss: 1.885491  [70000/160000]\n",
      "loss: 1.717232  [80000/160000]\n",
      "loss: 1.944709  [90000/160000]\n",
      "loss: 1.801247  [100000/160000]\n",
      "loss: 1.788665  [110000/160000]\n",
      "loss: 1.909135  [120000/160000]\n",
      "loss: 1.724221  [130000/160000]\n",
      "loss: 1.838874  [140000/160000]\n",
      "loss: 1.825472  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.017875 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.823117  [    0/160000]\n",
      "loss: 1.943723  [10000/160000]\n",
      "loss: 1.701002  [20000/160000]\n",
      "loss: 1.706808  [30000/160000]\n",
      "loss: 1.872146  [40000/160000]\n",
      "loss: 1.734457  [50000/160000]\n",
      "loss: 1.752036  [60000/160000]\n",
      "loss: 1.884760  [70000/160000]\n",
      "loss: 1.717434  [80000/160000]\n",
      "loss: 1.943838  [90000/160000]\n",
      "loss: 1.799250  [100000/160000]\n",
      "loss: 1.787365  [110000/160000]\n",
      "loss: 1.907725  [120000/160000]\n",
      "loss: 1.721415  [130000/160000]\n",
      "loss: 1.839021  [140000/160000]\n",
      "loss: 1.824105  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.017866 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.823723  [    0/160000]\n",
      "loss: 1.941600  [10000/160000]\n",
      "loss: 1.700803  [20000/160000]\n",
      "loss: 1.705563  [30000/160000]\n",
      "loss: 1.871930  [40000/160000]\n",
      "loss: 1.733942  [50000/160000]\n",
      "loss: 1.751494  [60000/160000]\n",
      "loss: 1.883932  [70000/160000]\n",
      "loss: 1.717660  [80000/160000]\n",
      "loss: 1.942835  [90000/160000]\n",
      "loss: 1.797506  [100000/160000]\n",
      "loss: 1.786262  [110000/160000]\n",
      "loss: 1.906347  [120000/160000]\n",
      "loss: 1.719000  [130000/160000]\n",
      "loss: 1.839049  [140000/160000]\n",
      "loss: 1.822914  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.017857 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.824302  [    0/160000]\n",
      "loss: 1.939608  [10000/160000]\n",
      "loss: 1.700495  [20000/160000]\n",
      "loss: 1.704327  [30000/160000]\n",
      "loss: 1.871811  [40000/160000]\n",
      "loss: 1.733556  [50000/160000]\n",
      "loss: 1.751023  [60000/160000]\n",
      "loss: 1.883392  [70000/160000]\n",
      "loss: 1.717971  [80000/160000]\n",
      "loss: 1.942137  [90000/160000]\n",
      "loss: 1.795705  [100000/160000]\n",
      "loss: 1.785190  [110000/160000]\n",
      "loss: 1.905222  [120000/160000]\n",
      "loss: 1.716889  [130000/160000]\n",
      "loss: 1.839048  [140000/160000]\n",
      "loss: 1.821881  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.017849 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.824631  [    0/160000]\n",
      "loss: 1.937493  [10000/160000]\n",
      "loss: 1.700216  [20000/160000]\n",
      "loss: 1.703223  [30000/160000]\n",
      "loss: 1.871881  [40000/160000]\n",
      "loss: 1.733353  [50000/160000]\n",
      "loss: 1.750672  [60000/160000]\n",
      "loss: 1.882621  [70000/160000]\n",
      "loss: 1.718126  [80000/160000]\n",
      "loss: 1.941494  [90000/160000]\n",
      "loss: 1.794215  [100000/160000]\n",
      "loss: 1.784168  [110000/160000]\n",
      "loss: 1.904319  [120000/160000]\n",
      "loss: 1.714989  [130000/160000]\n",
      "loss: 1.838918  [140000/160000]\n",
      "loss: 1.820667  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.017842 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.824952  [    0/160000]\n",
      "loss: 1.935474  [10000/160000]\n",
      "loss: 1.699969  [20000/160000]\n",
      "loss: 1.702367  [30000/160000]\n",
      "loss: 1.872104  [40000/160000]\n",
      "loss: 1.733132  [50000/160000]\n",
      "loss: 1.750384  [60000/160000]\n",
      "loss: 1.881838  [70000/160000]\n",
      "loss: 1.718633  [80000/160000]\n",
      "loss: 1.940761  [90000/160000]\n",
      "loss: 1.792762  [100000/160000]\n",
      "loss: 1.783283  [110000/160000]\n",
      "loss: 1.903666  [120000/160000]\n",
      "loss: 1.713363  [130000/160000]\n",
      "loss: 1.839069  [140000/160000]\n",
      "loss: 1.819504  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.017835 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.825057  [    0/160000]\n",
      "loss: 1.933482  [10000/160000]\n",
      "loss: 1.699553  [20000/160000]\n",
      "loss: 1.701573  [30000/160000]\n",
      "loss: 1.872302  [40000/160000]\n",
      "loss: 1.732702  [50000/160000]\n",
      "loss: 1.750215  [60000/160000]\n",
      "loss: 1.881107  [70000/160000]\n",
      "loss: 1.718872  [80000/160000]\n",
      "loss: 1.940188  [90000/160000]\n",
      "loss: 1.791369  [100000/160000]\n",
      "loss: 1.782541  [110000/160000]\n",
      "loss: 1.902896  [120000/160000]\n",
      "loss: 1.711857  [130000/160000]\n",
      "loss: 1.839117  [140000/160000]\n",
      "loss: 1.818171  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.017828 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.825014  [    0/160000]\n",
      "loss: 1.931646  [10000/160000]\n",
      "loss: 1.699504  [20000/160000]\n",
      "loss: 1.700867  [30000/160000]\n",
      "loss: 1.872353  [40000/160000]\n",
      "loss: 1.732340  [50000/160000]\n",
      "loss: 1.750046  [60000/160000]\n",
      "loss: 1.880461  [70000/160000]\n",
      "loss: 1.719048  [80000/160000]\n",
      "loss: 1.939852  [90000/160000]\n",
      "loss: 1.789982  [100000/160000]\n",
      "loss: 1.781871  [110000/160000]\n",
      "loss: 1.901827  [120000/160000]\n",
      "loss: 1.710597  [130000/160000]\n",
      "loss: 1.839219  [140000/160000]\n",
      "loss: 1.816763  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.017822 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.825398  [    0/160000]\n",
      "loss: 1.929846  [10000/160000]\n",
      "loss: 1.699399  [20000/160000]\n",
      "loss: 1.700341  [30000/160000]\n",
      "loss: 1.872494  [40000/160000]\n",
      "loss: 1.732092  [50000/160000]\n",
      "loss: 1.750114  [60000/160000]\n",
      "loss: 1.880023  [70000/160000]\n",
      "loss: 1.719171  [80000/160000]\n",
      "loss: 1.939633  [90000/160000]\n",
      "loss: 1.788496  [100000/160000]\n",
      "loss: 1.781208  [110000/160000]\n",
      "loss: 1.900900  [120000/160000]\n",
      "loss: 1.709391  [130000/160000]\n",
      "loss: 1.838938  [140000/160000]\n",
      "loss: 1.815529  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.017816 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.825619  [    0/160000]\n",
      "loss: 1.928124  [10000/160000]\n",
      "loss: 1.699318  [20000/160000]\n",
      "loss: 1.699544  [30000/160000]\n",
      "loss: 1.872866  [40000/160000]\n",
      "loss: 1.732174  [50000/160000]\n",
      "loss: 1.749943  [60000/160000]\n",
      "loss: 1.879780  [70000/160000]\n",
      "loss: 1.719358  [80000/160000]\n",
      "loss: 1.939296  [90000/160000]\n",
      "loss: 1.787049  [100000/160000]\n",
      "loss: 1.780638  [110000/160000]\n",
      "loss: 1.899997  [120000/160000]\n",
      "loss: 1.708308  [130000/160000]\n",
      "loss: 1.838679  [140000/160000]\n",
      "loss: 1.814267  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.017810 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.825632  [    0/160000]\n",
      "loss: 1.926555  [10000/160000]\n",
      "loss: 1.699178  [20000/160000]\n",
      "loss: 1.698613  [30000/160000]\n",
      "loss: 1.873432  [40000/160000]\n",
      "loss: 1.732341  [50000/160000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.750081  [60000/160000]\n",
      "loss: 1.879449  [70000/160000]\n",
      "loss: 1.719469  [80000/160000]\n",
      "loss: 1.938959  [90000/160000]\n",
      "loss: 1.785555  [100000/160000]\n",
      "loss: 1.780136  [110000/160000]\n",
      "loss: 1.898960  [120000/160000]\n",
      "loss: 1.707216  [130000/160000]\n",
      "loss: 1.838159  [140000/160000]\n",
      "loss: 1.813495  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.017805 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.825559  [    0/160000]\n",
      "loss: 1.924942  [10000/160000]\n",
      "loss: 1.699211  [20000/160000]\n",
      "loss: 1.697813  [30000/160000]\n",
      "loss: 1.873858  [40000/160000]\n",
      "loss: 1.732333  [50000/160000]\n",
      "loss: 1.750061  [60000/160000]\n",
      "loss: 1.879036  [70000/160000]\n",
      "loss: 1.719653  [80000/160000]\n",
      "loss: 1.938648  [90000/160000]\n",
      "loss: 1.784239  [100000/160000]\n",
      "loss: 1.779630  [110000/160000]\n",
      "loss: 1.897974  [120000/160000]\n",
      "loss: 1.706138  [130000/160000]\n",
      "loss: 1.838199  [140000/160000]\n",
      "loss: 1.812239  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.017800 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.825937  [    0/160000]\n",
      "loss: 1.923174  [10000/160000]\n",
      "loss: 1.699347  [20000/160000]\n",
      "loss: 1.697330  [30000/160000]\n",
      "loss: 1.874426  [40000/160000]\n",
      "loss: 1.732112  [50000/160000]\n",
      "loss: 1.749937  [60000/160000]\n",
      "loss: 1.878611  [70000/160000]\n",
      "loss: 1.719635  [80000/160000]\n",
      "loss: 1.938202  [90000/160000]\n",
      "loss: 1.782925  [100000/160000]\n",
      "loss: 1.778941  [110000/160000]\n",
      "loss: 1.897376  [120000/160000]\n",
      "loss: 1.705349  [130000/160000]\n",
      "loss: 1.838046  [140000/160000]\n",
      "loss: 1.811347  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.017795 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.826117  [    0/160000]\n",
      "loss: 1.921623  [10000/160000]\n",
      "loss: 1.699502  [20000/160000]\n",
      "loss: 1.696644  [30000/160000]\n",
      "loss: 1.875092  [40000/160000]\n",
      "loss: 1.731952  [50000/160000]\n",
      "loss: 1.750033  [60000/160000]\n",
      "loss: 1.878404  [70000/160000]\n",
      "loss: 1.719555  [80000/160000]\n",
      "loss: 1.937762  [90000/160000]\n",
      "loss: 1.781404  [100000/160000]\n",
      "loss: 1.778547  [110000/160000]\n",
      "loss: 1.896612  [120000/160000]\n",
      "loss: 1.704999  [130000/160000]\n",
      "loss: 1.837879  [140000/160000]\n",
      "loss: 1.810345  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 0.017790 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.826135  [    0/160000]\n",
      "loss: 1.920028  [10000/160000]\n",
      "loss: 1.699437  [20000/160000]\n",
      "loss: 1.695772  [30000/160000]\n",
      "loss: 1.875665  [40000/160000]\n",
      "loss: 1.732092  [50000/160000]\n",
      "loss: 1.750183  [60000/160000]\n",
      "loss: 1.878138  [70000/160000]\n",
      "loss: 1.719372  [80000/160000]\n",
      "loss: 1.937292  [90000/160000]\n",
      "loss: 1.779779  [100000/160000]\n",
      "loss: 1.778184  [110000/160000]\n",
      "loss: 1.895951  [120000/160000]\n",
      "loss: 1.704587  [130000/160000]\n",
      "loss: 1.837806  [140000/160000]\n",
      "loss: 1.809043  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.017786 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.826322  [    0/160000]\n",
      "loss: 1.918512  [10000/160000]\n",
      "loss: 1.699256  [20000/160000]\n",
      "loss: 1.695050  [30000/160000]\n",
      "loss: 1.876309  [40000/160000]\n",
      "loss: 1.732303  [50000/160000]\n",
      "loss: 1.750225  [60000/160000]\n",
      "loss: 1.877717  [70000/160000]\n",
      "loss: 1.719200  [80000/160000]\n",
      "loss: 1.936941  [90000/160000]\n",
      "loss: 1.778375  [100000/160000]\n",
      "loss: 1.777874  [110000/160000]\n",
      "loss: 1.895453  [120000/160000]\n",
      "loss: 1.704189  [130000/160000]\n",
      "loss: 1.837879  [140000/160000]\n",
      "loss: 1.807936  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 0.017782 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.826257  [    0/160000]\n",
      "loss: 1.917160  [10000/160000]\n",
      "loss: 1.698904  [20000/160000]\n",
      "loss: 1.694320  [30000/160000]\n",
      "loss: 1.876894  [40000/160000]\n",
      "loss: 1.732238  [50000/160000]\n",
      "loss: 1.750330  [60000/160000]\n",
      "loss: 1.877292  [70000/160000]\n",
      "loss: 1.719033  [80000/160000]\n",
      "loss: 1.936578  [90000/160000]\n",
      "loss: 1.777088  [100000/160000]\n",
      "loss: 1.777339  [110000/160000]\n",
      "loss: 1.894810  [120000/160000]\n",
      "loss: 1.703855  [130000/160000]\n",
      "loss: 1.837659  [140000/160000]\n",
      "loss: 1.806783  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 0.017778 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.826186  [    0/160000]\n",
      "loss: 1.915619  [10000/160000]\n",
      "loss: 1.698856  [20000/160000]\n",
      "loss: 1.693620  [30000/160000]\n",
      "loss: 1.877441  [40000/160000]\n",
      "loss: 1.732351  [50000/160000]\n",
      "loss: 1.750273  [60000/160000]\n",
      "loss: 1.876963  [70000/160000]\n",
      "loss: 1.719170  [80000/160000]\n",
      "loss: 1.936152  [90000/160000]\n",
      "loss: 1.775690  [100000/160000]\n",
      "loss: 1.776930  [110000/160000]\n",
      "loss: 1.894361  [120000/160000]\n",
      "loss: 1.703528  [130000/160000]\n",
      "loss: 1.837518  [140000/160000]\n",
      "loss: 1.805868  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 0.017774 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.826241  [    0/160000]\n",
      "loss: 1.914288  [10000/160000]\n",
      "loss: 1.698717  [20000/160000]\n",
      "loss: 1.693106  [30000/160000]\n",
      "loss: 1.877754  [40000/160000]\n",
      "loss: 1.732013  [50000/160000]\n",
      "loss: 1.750252  [60000/160000]\n",
      "loss: 1.876615  [70000/160000]\n",
      "loss: 1.719431  [80000/160000]\n",
      "loss: 1.935627  [90000/160000]\n",
      "loss: 1.774251  [100000/160000]\n",
      "loss: 1.776537  [110000/160000]\n",
      "loss: 1.893647  [120000/160000]\n",
      "loss: 1.703387  [130000/160000]\n",
      "loss: 1.837401  [140000/160000]\n",
      "loss: 1.804721  [150000/160000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.017770 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "469de2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nn.functional.softmax(model(torch.tensor(final_test.values.astype(np.float32))),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cbed650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 9])\n"
     ]
    }
   ],
   "source": [
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3c2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(y.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78a9f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>Class_5</th>\n",
       "      <th>Class_6</th>\n",
       "      <th>Class_7</th>\n",
       "      <th>Class_8</th>\n",
       "      <th>Class_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050426</td>\n",
       "      <td>0.402919</td>\n",
       "      <td>0.148458</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.071508</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.076371</td>\n",
       "      <td>0.160727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034143</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.036009</td>\n",
       "      <td>0.463141</td>\n",
       "      <td>0.352603</td>\n",
       "      <td>0.066486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029566</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.191856</td>\n",
       "      <td>0.414550</td>\n",
       "      <td>0.170723</td>\n",
       "      <td>0.168074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044152</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.028519</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.569710</td>\n",
       "      <td>0.123379</td>\n",
       "      <td>0.171478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050926</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.413919</td>\n",
       "      <td>0.265673</td>\n",
       "      <td>0.222805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class_1   Class_2   Class_3   Class_4   Class_5   Class_6   Class_7  \\\n",
       "0  0.050426  0.402919  0.148458  0.019904  0.019904  0.071508  0.049783   \n",
       "1  0.034143  0.011562  0.011562  0.012933  0.011562  0.036009  0.463141   \n",
       "2  0.029566  0.005584  0.005584  0.008478  0.005584  0.191856  0.414550   \n",
       "3  0.044152  0.015690  0.015690  0.028519  0.015690  0.015690  0.569710   \n",
       "4  0.050926  0.008723  0.010947  0.009560  0.008723  0.008723  0.413919   \n",
       "\n",
       "    Class_8   Class_9  \n",
       "0  0.076371  0.160727  \n",
       "1  0.352603  0.066486  \n",
       "2  0.170723  0.168074  \n",
       "3  0.123379  0.171478  \n",
       "4  0.265673  0.222805  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis = [f\"Class_{i}\" for i in range(1,10)]\n",
    "sub.columns = lis\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7d7eb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>Class_5</th>\n",
       "      <th>Class_6</th>\n",
       "      <th>Class_7</th>\n",
       "      <th>Class_8</th>\n",
       "      <th>Class_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.050426</td>\n",
       "      <td>0.402919</td>\n",
       "      <td>0.148458</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.071508</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.076371</td>\n",
       "      <td>0.160727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0.034143</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.036009</td>\n",
       "      <td>0.463141</td>\n",
       "      <td>0.352603</td>\n",
       "      <td>0.066486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.191856</td>\n",
       "      <td>0.414550</td>\n",
       "      <td>0.170723</td>\n",
       "      <td>0.168074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.028519</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.569710</td>\n",
       "      <td>0.123379</td>\n",
       "      <td>0.171478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0.050926</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.413919</td>\n",
       "      <td>0.265673</td>\n",
       "      <td>0.222805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   Class_1   Class_2   Class_3   Class_4   Class_5   Class_6  \\\n",
       "0  200000  0.050426  0.402919  0.148458  0.019904  0.019904  0.071508   \n",
       "1  200001  0.034143  0.011562  0.011562  0.012933  0.011562  0.036009   \n",
       "2  200002  0.029566  0.005584  0.005584  0.008478  0.005584  0.191856   \n",
       "3  200003  0.044152  0.015690  0.015690  0.028519  0.015690  0.015690   \n",
       "4  200004  0.050926  0.008723  0.010947  0.009560  0.008723  0.008723   \n",
       "\n",
       "    Class_7   Class_8   Class_9  \n",
       "0  0.049783  0.076371  0.160727  \n",
       "1  0.463141  0.352603  0.066486  \n",
       "2  0.414550  0.170723  0.168074  \n",
       "3  0.569710  0.123379  0.171478  \n",
       "4  0.413919  0.265673  0.222805  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = pd.concat([iden,sub],axis = 1)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7a157d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>Class_5</th>\n",
       "      <th>Class_6</th>\n",
       "      <th>Class_7</th>\n",
       "      <th>Class_8</th>\n",
       "      <th>Class_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.4029</td>\n",
       "      <td>0.1485</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.1607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.4631</td>\n",
       "      <td>0.3526</td>\n",
       "      <td>0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.1919</td>\n",
       "      <td>0.4145</td>\n",
       "      <td>0.1707</td>\n",
       "      <td>0.1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>0.2657</td>\n",
       "      <td>0.2228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Class_1  Class_2  Class_3  Class_4  Class_5  Class_6  Class_7  \\\n",
       "0  200000   0.0504   0.4029   0.1485   0.0199   0.0199   0.0715   0.0498   \n",
       "1  200001   0.0341   0.0116   0.0116   0.0129   0.0116   0.0360   0.4631   \n",
       "2  200002   0.0296   0.0056   0.0056   0.0085   0.0056   0.1919   0.4145   \n",
       "3  200003   0.0442   0.0157   0.0157   0.0285   0.0157   0.0157   0.5697   \n",
       "4  200004   0.0509   0.0087   0.0109   0.0096   0.0087   0.0087   0.4139   \n",
       "\n",
       "   Class_8  Class_9  \n",
       "0   0.0764   0.1607  \n",
       "1   0.3526   0.0665  \n",
       "2   0.1707   0.1681  \n",
       "3   0.1234   0.1715  \n",
       "4   0.2657   0.2228  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    subm[f\"Class_{i}\"] = subm[f\"Class_{i}\"].round(decimals = 4)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1845a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('submissionfinal.csv',index = False,header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a8982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
